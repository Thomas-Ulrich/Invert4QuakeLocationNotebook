{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right; width: 320px; display: inline\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/LMU_Muenchen_Logo.svg/2000px-LMU_Muenchen_Logo.svg.png\">\n",
    "<p>  \n",
    "    <font face='Helvetica' size='5.6'><b>Seismology Computer Lab: Locating Earthquakes</b></font><br><br> \n",
    "    <font face='Helvetica' size='4.6'>Ludwig-Maximilians-Universität München</font><br> \n",
    "    <font face='Helvetica' size='3'>Dr. Alice-Agnes Gabriel, based on work of Karin Sigloch</font><br> \n",
    "    <font face='Helvetica' size='3'>Python v. translated by Noah Luna</font> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part I: Background</h2>\n",
    "\n",
    "<p>This lab deals with earthquake location as an example of a small, non-linear, but linearizable inverse problem. Earthquake location is a basic and important service that seismologists deliver, usually through national or regional earthquake services. An example would be the Bavarian earthquake service run by LMU (Bayrischer Erdbebendienst, a.k.a. “BayWatch”), which currently deploys 24 seismic stations across the state. The rapid detection and location of a quake is important for immediate emergency response and for mitigation of future earthquake damage, which will usually occur in a similar location.</p>\n",
    "\n",
    "<p>Our monitoring network here consists of $10$ seismic stations distributed irregularly over a surface area of 50 km $\\times$ 50 km. Our data $d$ are the measured arrival times $T_{i}$ of the first-arriving P-waves. There is a time measurement uncertainty $\\sigma_{i}^{(d)}$ associated with reading $T_{i}$ from a seismogram. This uncertainty is related to the time interval it takes for the emergent amplitude to clearly rise above the ambient seismic noise. We assume that our measurements $T_{i}$ are uncorrelated and that the standard deviation of the measurement error is the same for all measurements $i$: $\\sigma_{i}^{(d)} = \\sigma$</p>\n",
    "\n",
    "<p>In this lab exercise, the data $T_{i}$ are generated synthetically/analytically, by solving the forward problem $d = g(m)$ and adding some Gaussian noise to mimic real-world conditions. Compared to measuring real data in the field, this is kind of cheating of course. But actually knowing the true solution allows us to assess and compare the performance of different designs for the network geometry. (A good idea before spending a lot of money on hardware.)</p>\n",
    "\n",
    "<p>As a simplification, we assume that P-wave velocity in the area of the network is a constant and known quantity (v = 5 km/s). The forward problem then takes the non-linear but simple analytical form</p>\n",
    "\n",
    "$$d_{i} = T_{i}(x_{i},y_{i}) + t = \\frac{1}{v} \\sqrt{(x_{i}-x_{s})^2 + (y_{i}-y_{s})^2 + (z_{i}-z_{s})^2 } + t $$\n",
    "\n",
    "<p>where $m = (x_{s}, y_{s}, z_{s}, t)$ are the four parameters to estimate (source longitude, latitude, depth, and time of rupture), and xi are the station locations.</p>\n",
    "\n",
    "<ol>\n",
    "    <li>How would you informally describe the modeling assumptions/physics expressed by\n",
    "        the forward formula above?</li>\n",
    "    <li>Why is this a non-linear inverse problem?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more realistic, non-homogeneous media, the forward problem gets quite involved, but this does not really change the characteristics of the inverse problem, which we are about to explore. In order for the inverse problem to be linearizable from $d = g(m)$ to $d = Gm$, we need a rough starting guess $m_{0} = (x_{0}, y_{0}, z_{0}, t_{0})$ for where the earthquake occurred. (The default guess lies in the rough area where earthquakes always tend to come from, e.g. where the last quake happened.) We linearize by computing the first derivative of each datum with respect to each parameter (first term in the Taylor expansion) around the point $m_{0}$, and neglecting all higher-order derivatives:\n",
    "\n",
    "$$G_{ij} = \\frac{\\partial d_{i}}{m_{j}}\\mid_{m=m_{0}}$$\n",
    "\n",
    "<p>For example, element $G_{12}$ of matrix $G$ is the partial derivative of arrival time at station $1$ $(T_{1})$ with respect to source latitude $y_{s0}$.</p>\n",
    "<p>Our software computes the so-called “least-squares solution”, which minimizes the $L_{2}$ norm of $\\|d−Gm\\|_{2}$:</p>\n",
    "\n",
    "$$m^{lsq} = G^{-g}d$$\n",
    "where\n",
    "$$G^{-g}= (G^{T}G)^{-1}G^{T} $$\n",
    "\n",
    "<p>By solving this linear problem repeatedly, we hope to converge toward the true solution of the nonlinear problem. Using $G|_{m=m_{0}}$, we update the solution to $m_{1} = (x_{1}, y_{1}, z_{1}, t_{1})$, which is hopefully closer to the real quake location than $m_{0}$. We recompute the partial derivatives for $G\\mid_{m=m_{1}}$, solve for $m_{2}$, and so on, until $m$ no longer changes. Whether and how this procedure converges toward the true quake location is the subject of this lab.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part II: Experiment</h2>\n",
    "\n",
    "<p>First, execute Cell II.A  to import the necessary libraries and modules.</p>\n",
    "\n",
    "<p>Read over and then run Cell II.B. Lines 1-6 of this cell contain parameter settings you will need to modify in the course of this lab. You will be doing many runs of this program, so keep a log with notes about individual runs. <b>In the end, write a lab report summing up your findings with a few of the most informative plots, sketches and text.</b></p>\n",
    "\n",
    "<p>The true location of <span style=\"font-family: Courier;\">event1</span>, as well as its starting guess <span style=\"font-family: Courier;\">guess1</span>, are located inside the area of the sensor network. Do a number of runs using <span style=\"font-family: Courier;\">event1</span>, first with minimal noise\n",
    "(e.g., $\\sigma = 0.01$ s), then with increasing amounts of noise. For real seismograms, the reading uncertainty could easily amount to 0.2 s or more. Each noise realization is different, so it is interesting to do multiple runs for identical noise levels.</p>\n",
    "<p><h3>Observations:</h3>\n",
    "<ol>\n",
    "    <li>How many iterations it takes for the solution to converge, and how much each iteration contributes to reducing the predicted misfit.</li>\n",
    "    <li>How close each component of the final solution is to the true earthquake location.</li>\n",
    "    <li>To assess whether the inversion works properly, we often consider a statistic called normalized\n",
    "prediction error (or “normalized chi-square”):\n",
    "\n",
    "\n",
    "$$ \\chi^{2} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{(T_{i}^{obs} - T_{i}^{pred})^2}{\\sigma^{2}}$$\n",
    "\n",
    "$ \\chi^{2}$ should be on the order of 1. This is the case when most or all summation terms are on the order of 1. Describe in words the physical meaning of the expression inside the sum.\n",
    "So why can we expect an acceptable solution to produce a $ \\chi^{2} \\approx 1$?<br>\n",
    "(When working with real data, we need to know/estimate $\\sigma$ a priori. Sometimes it happens that we obtain chi-squares that are orders of magnitude different from 1. What is the likely problem in such a case?)</li>\n",
    "<li>Note whether in your runs, $ \\chi^{2} \\approx 1$? (screen output).</li>\n",
    "<li>Whether, at some noise level, the solution no longer converges. What exactly happens\n",
    "(divergence, oscillations,...)? What is the reason?</li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cell II.A [Run this first]</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from numpy import matrix\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "#Function to retrieve eigenvalues and eigenvectors from covariance matrix.\n",
    "def eigsorted(cov):\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    return vals[order], vecs[:,order]\n",
    "\n",
    "#True velocity of the crust beneath the seismic network:\n",
    "v = 5.0 #km/s\n",
    "\n",
    "def compute_distance_arrival_time(xyzt, xyz_receivers):\n",
    "    #predicted src/rcv distances and travel times in this iteration\n",
    "    dist = np.sqrt( np.power(xyzt[0]-xyz_receivers[:,0],2) + \n",
    "                   np.power(xyzt[1]-xyz_receivers[:,1],2)+ np.power(xyzt[2]-xyz_receivers[:,2],2))\n",
    "    arrival_time = xyzt[3] + (dist/v)\n",
    "    return (dist, arrival_time)\n",
    "\n",
    "def compute_GT(xyzt, dist):\n",
    "    # Partial derivatives --> G matrix\n",
    "    dTdxs = (xyzt[0] - xyz_receivers[:,0]) / (dist * v)\n",
    "    dTdys = (xyzt[1] - xyz_receivers[:,1]) / (dist * v)\n",
    "    dTdzs = (xyzt[2] - xyz_receivers[:,2]) / (dist * v)\n",
    "    nr = xyz_receivers.shape[0]\n",
    "    dTdts = np.ones(nr)\n",
    "    dTdts = np.ones(nr)\n",
    "    return np.matrix( [dTdxs, dTdys,dTdzs, dTdts] )\n",
    "\n",
    "\n",
    "def compute_generalized_inverse(G, GT):\n",
    "    Gg =  np.linalg.pinv(GT * G) * GT\n",
    "    return Gg\n",
    "\n",
    "    ##Alternate form:#\n",
    "    ##Singular value decomposition\n",
    "    #U, LP, VT = np.linalg.svd(G)\n",
    "    #V = VT.transpose()\n",
    "    #L = np.zeros((nrcv,4), float)\n",
    "    #np.fill_diagonal(L, LP)\n",
    "    #Gg = V * np.linalg.pinv(L) *  np.transpose(U) #generalized inverse\n",
    "    deltam = Gg * deltad.reshape(nrcv,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cell II.B</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Initial guess for earthquake location and time: x y z t\n",
    "event1 = np.array([0.0, 0.0, 10.0, 0.0])\n",
    "guess1 = np.array([3.0, 4.0,  20.0,  2.0])\n",
    "\n",
    "event2 = np.array([40.0, 60.0, 10.0, 0.0])\n",
    "guess2 = np.array([35.0, 65.0, 20.0, 2.0])\n",
    "\n",
    "##Edit here to select an event\n",
    "event = event1\n",
    "guess = guess1\n",
    "\n",
    "##EDIT HERE: Standard deviation of the Gaussian measurement noise that is\n",
    "# assumed to be present in each traveltime measurement.\n",
    "sigma_d = 0.1;  # in sec\n",
    "\n",
    "# We are inverting for xs, ys, zs, ts\n",
    "xs_true = event[0]\n",
    "ys_true = event[1]\n",
    "zs_true = event[2]\n",
    "ts_true = event[3]\n",
    "\n",
    "#Initial guess.\n",
    "xs0 = guess[0]\n",
    "ys0 = guess[1]\n",
    "zs0 = guess[2]\n",
    "ts0 = guess[3]\n",
    "\n",
    "\n",
    "#Seismic receiver locations (in km)\n",
    "nrcv = 10\n",
    "xyz_receivers = np.zeros((nrcv,3))\n",
    "xyz_receivers[:,0] = [ 35.0, -44.0, -11.0, 23.0, 42.0, -12.0, -45.0, 5.0, -1.0, 20.0]\n",
    "xyz_receivers[:,1] = [ 9.0, 10.0, -25.0, -39.0, -27.0, 50.0, 16.0, -19.0, -11.0, 11.0]\n",
    "\n",
    "\n",
    "#Make the true \"data\" T_true: arrival times at stations:\n",
    "R_true, T_true = compute_distance_arrival_time(event, xyz_receivers)\n",
    "\n",
    "#Let's make some noise:\n",
    "eps = (2.2204**-16)\n",
    "\n",
    "xyzt_true = np.array([xs_true, ys_true, zs_true, ts_true ])\n",
    "sigma_d = sigma_d + eps \n",
    "\n",
    "\n",
    "##Maximum number of iterations\n",
    "kmaxer = 100\n",
    "\n",
    "\n",
    "#Initialize arrays xyzt, R, and T with dimensions specified by max. # of iter.\n",
    "xyzt = np.zeros((kmaxer,4))\n",
    "\n",
    "#Initial guess for solution\n",
    "xyzt[:] = [xs0, ys0, zs0, ts0] \n",
    "stds = np.zeros((kmaxer,4))\n",
    "\n",
    "R = np.zeros((nrcv,1))\n",
    "T = np.zeros((nrcv,1))\n",
    "\n",
    "#Data with measurement noise\n",
    "T_obs = T_true + sigma_d * np.random.randn(nrcv) \n",
    "\n",
    "#Loop starts here\n",
    "for k in range(0,kmaxer):\n",
    "    #clear previous output\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    xs, ys,zs, ts = xyzt[k,0], xyzt[k,1], xyzt[k,2], xyzt[k,3]\n",
    "\n",
    "    #predicted src/rcv distances and travel times in this iteration\n",
    "    R[:,k], T[:,k] = compute_distance_arrival_time(xyzt[k,:], xyz_receivers)\n",
    "    \n",
    "    #deltad = G*deltam\n",
    "    deltad = T_obs[:] - T[:,k]\n",
    "\n",
    "    GT = compute_GT(xyzt[k,:], R[:,k])\n",
    "    G = GT.transpose()\n",
    "    Gg = compute_generalized_inverse(G, GT)\n",
    "    deltam = Gg * deltad.reshape(nrcv,1)\n",
    "    \n",
    "    #Update m(k+1) = m(k)+deltam(k)\n",
    "    xyzt[k+1,:]  = xyzt[k,:] + deltam.transpose()\n",
    "    \n",
    "    ## Update uncertainties\n",
    "    # Error propagation: covariance matrix of the model\n",
    "    # We assume the measurement noise in the data is uncorrelated\n",
    "    # between measurements, and that the standard deviation of the\n",
    "    # measurement noise is sigma_d\n",
    "    CVM = inv(G.transpose()*G)\n",
    "    cv = CVM * (np.power(sigma_d , 2))\n",
    "    stds[k+1,0:4] = np.sqrt(  np.diag(cv) )\n",
    " \n",
    "    #Update distances and predicted times\n",
    "    klast = k\n",
    "\n",
    "    ###Print result##### \n",
    "    print()\n",
    "    print('-'*40)\n",
    "    print('Iteration {}'.format(klast))\n",
    "    print('-'*40,'\\n')\n",
    "    print('Standard deviation sigma_d of measurement uncertainty (in sec): {:5.2f}'.format(sigma_d))\n",
    "    print('\\nTrue Solution')\n",
    "    print('{}{}{}{}{}{}{}{}'.format(' '*8,'xs(km)',' '*8,'ys(km)',' '*8,'zs(km)',\n",
    "                                ' '*8,'ts(s)'))\n",
    "    print('{:13.2f}{:14.2f}{:14.2f}{:14.2f}'.format(xyzt_true[0], xyzt_true[1], \n",
    "                                                xyzt_true[2],xyzt_true[3]))\n",
    "    print('\\nEstimated solutions and their estimated standard deviations')\n",
    "    print(' {}    {}    {}    {}    {}    {}    {}    {}    {}'.format('iter','xs(km)',\n",
    "                                                                       'ys(km)','zs(km)',\n",
    "                                                                       'ts(km)','std(xs)',\n",
    "                                                                       'std(ys)','std(zs)',\n",
    "                                                                       'std(ts)'))\n",
    "\n",
    "    for i in range(0,klast+1): \n",
    "        print('{:4.0f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:11.2f}{:11.2f}{:11.2f}{:11.2f}'.\n",
    "              format(i,xyzt[i,0], xyzt[i,1], xyzt[i,2], xyzt[i,3],\n",
    "                     stds[i,0],stds[i,1],stds[i,2],stds[i,3]))\n",
    "    print()\n",
    "    \n",
    "    dd = 5\n",
    "    xli = xs_true + [-dd, dd]\n",
    "    yli = ys_true + [-dd, dd]\n",
    "      \n",
    "    ##Error Ellipse##\n",
    "    #Get eigenvalues and eigenvectors from covariance matrix. Which \n",
    "    #  we use to get the width and height of covariance error\n",
    "    #  ellipse\n",
    "    vals, vecs = eigsorted(cv[0:2,0:2])\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "    \n",
    "    #nstd : The radius of the ellipse in numbers of standard deviations.\n",
    "    #  where n = the set of natural numbers n = 1,2...,n corresponding\n",
    "    #  to n standard deviations. \n",
    "    #  For one-sigma ellipse/one std set ntsd = 1 (As described in text).\n",
    "    nstd = 1\n",
    "    \n",
    "    # Width and height are \"full\" widths, not radius.\n",
    "    width, height = 2 * nstd * np.sqrt(vals)\n",
    "    \n",
    "    ellip = Ellipse(xy=(xyzt[klast ,0] ,xyzt[klast,1]), width=width,\n",
    "                    height=height, angle=theta,color='k')    \n",
    "    \n",
    "    ##Plots##\n",
    "    #Set up fig and define number of axes\n",
    "    numrows = 1\n",
    "    numcols = 2\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
    "\n",
    "    #Name of plots to be used later.\n",
    "    titles = ['Map View', 'Zoomed Around Source']\n",
    "\n",
    "    for i in range(0, numcols):   \n",
    "            \n",
    "        #Seismic Stations\n",
    "        axes[i].scatter(xyz_receivers[:,0],xyz_receivers[:,1],marker=\"^\",c=\"blue\", label=\"stations\", s=80)\n",
    "\n",
    "        #True source\n",
    "        axes[i].scatter(xs_true, ys_true, marker=\"*\",c=\"red\", \n",
    "                    label=\"true source location\",s=370)\n",
    "\n",
    "        #Estimated locations\n",
    "        axes[i].scatter(xyzt[0:klast + 1,0],xyzt[0:klast + 1,1],marker=\"x\",\n",
    "                        c=\"black\",s=100,linewidth = .8)\n",
    "        axes[i].plot(xyzt[0:klast + 1,0],xyzt[0:klast + 1,1],marker=\"_\",\n",
    "                     c=\"black\", linewidth=.8)\n",
    "        \n",
    "        \"\"\"\n",
    "        #For some reason, this makes the plot very small\n",
    "        #Label stations\n",
    "        for j in range(nrcv):\n",
    "            axes[i].annotate('station {}'.format(j+1), xy=(xyz_receivers[j,0],xyz_receivers[j,1]),\n",
    "                             xytext=(xyz_receivers[j,0]-0.15, xyz_receivers[j,0]-0.15), textcoords='offset points')\n",
    "        \"\"\"\n",
    "        #Set xlim and ylim for zoomed plot.\n",
    "        if i == 1:\n",
    "            axes[i].set_xlim((xli[0],xli[1]))\n",
    "            axes[i].set_ylim((yli[0],yli[1]))\n",
    "         \n",
    "        #Plot Ellipse Artist to Zoomed Plot\n",
    "        axes[1].add_patch(ellip)\n",
    "        ellip.set_facecolor('none')\n",
    "    \n",
    "        #X and Y labels\n",
    "        axes[i].set_xlabel(r'$x(km)$', fontsize=13)\n",
    "        axes[i].set_ylabel(r'$y(km)$', fontsize=13)\n",
    "    \n",
    "        #Plot Titles\n",
    "        title = titles[i]\n",
    "        axes[i].set_title(title,fontsize=15)\n",
    "       \n",
    "        #Plot legend\n",
    "        axes[i].legend(markerscale=0.8)\n",
    "        \n",
    "        #Show grid\n",
    "        axes[i].grid(True)\n",
    "\n",
    "        #Make plots fit neatly in notebook\n",
    "        fig.tight_layout()\n",
    "\n",
    "    #Data misfit (normalized) plots\n",
    "    tmp = T.copy()\n",
    "    tmp2 = T.copy()\n",
    "    for jj in range(k+1):\n",
    "        tmp[:,jj]= T[:,jj]-T_true[:]\n",
    "        tmp2[:,jj]= T[:,jj]-T_obs[:]\n",
    "    \n",
    "    #Convergence of prediction error plots\n",
    "    cov = tmp2/sigma_d\n",
    "    row, col = cov.shape\n",
    "    my_list = list(range(1, nrcv+1))    \n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\n",
    "    for i in range(col):\n",
    "        #ax.scatter(my_list, cov[:,i], marker=\"x\", label='data {}'.format(i),linewidth=.8)\n",
    "        ax.plot(my_list, cov[:,i], marker=\"x\", label='run {}'.format(i), linewidth=.8)\n",
    "        \n",
    "\n",
    "    ax.plot([i for i in my_list],np.negative(np.ones(nrcv)),\n",
    "            color='#1912AE', marker='o',linewidth=.6, label=r'data - $\\sigma$')\n",
    "    ax.plot([i for i in my_list],np.zeros(nrcv),\n",
    "            color='#191279', marker='d',linewidth=.6, label='data')\n",
    "    ax.plot([i for i in my_list],np.ones(nrcv),\n",
    "            color='k', marker='^', linewidth=.6, label=r'data + $\\sigma$')\n",
    "\n",
    "\n",
    "    #Axes information\n",
    "    ax.set_xlim((1,10))\n",
    "    ax.set_xlabel('station number', fontsize=13)\n",
    "    ax.set_ylabel('normalized true error', fontsize=13)\n",
    "    ax.set_title(\"Convergence of (normalized) true error\",fontsize=15)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    ###END PLOTS #####\n",
    "    \n",
    "\n",
    "    #######GO AGAIN?#####\n",
    "    answer = input('\\nRun another iteration?: [y/n]: ')\n",
    "    try:\n",
    "        ans_val = answer.lower()[0]\n",
    "    except IndexError:\n",
    "        print('Please answer with ''yes'' or ''no''.\\n' )\n",
    "        continue\n",
    "    if ans_val == 'y':\n",
    "        print('You entered [yes].')\n",
    "        k += 1\n",
    "    elif ans_val == 'n':\n",
    "        print('Iteration cancelled.')\n",
    "        k += 1   \n",
    "        break\n",
    "    else:\n",
    "        print(\"\\nSorry, I do not understand.\\n\")\n",
    "        print(\"Please run again.\")\n",
    "        break\n",
    "        \n",
    "    #add one column to R and T    \n",
    "    R = np.column_stack((R,0*R[:,0]))\n",
    "    T = np.column_stack((T, 0*T[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b>  \n",
    "The convergence of (normalized) prediction error, $e$, is defined as:\n",
    "\n",
    "$$e = \\frac {T_{obs} - T_{pred} }{\\sigma_{d}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Error Propagation:</h3>\n",
    "\n",
    "<p>Run Cell III and answer the following:</p>\n",
    "<p>For the linear solution $m = G^{-g}d$, uncertainty propagates from the data to the model according to the relationship derived in class:\n",
    "$$[cov(m)] = G^{-g}[cov(d)(G^{-g})^{T}] $$\n",
    "<ol>\n",
    "    <li>For the least squares solution and uncorrelated measurements with a uniform variance of $\\sigma^{2}$, the above expression simplifies to:\n",
    "$$[cov(m)] = \\sigma^{2}(GG^{T})^{-1} $$\n",
    "Show that this is the case.</li>\n",
    "    <li>Both the model covariance matrix and the standard deviations of the model parameters are given as screen output. Verify that these two outputs are consistent.</li>\n",
    "    <li>For various noise and initial conditions, state the solution(s) of the inversion(s), with error bars:<br>\n",
    "$$x_{s} = ...km\\pm...km $$$$y_{s} = ...km\\pm...km $$$$z_{s} = ...km\\pm...km $$$$t_{s} = ...s\\pm...s $$ Does the true solution actually fall within these error bounds, to the extent that we would expect? When it does not, what are the likely reasons? (To assess $x_{s}$ and $y_{s}$, you can also use the plotted ellipses, which are one-sigma[$ntsd$ in code] ellipses of the Gaussian distribution, as described in the handout.)</li>   \n",
    "    <li>Correlation of parameter estimates: Some off-diagonal elements of $[cov(m)]$ are clearly non-zero. The negative values for $\\sigma_{zt}$ are a typical feature when locating earthquakes: an over-estimate of depth tends to coincide with an under-estimate of origin time. How is this explained?<br>   \n",
    "    </li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cell III</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Singular value decomposition\n",
    "U, LP, VT = np.linalg.svd(G)\n",
    "V = VT.transpose()\n",
    "L = np.zeros((nrcv,4), float)\n",
    "np.fill_diagonal(L, LP)\n",
    "\n",
    "print('Model covariance matrix cov[m]: cov[d] * inverse(transpose(G)*G)' )\n",
    "print(cv,'\\n')\n",
    "print('Normalized model covariance matrix cov[m]/sigma_d = inv(transpose(G)*G):')\n",
    "print(CVM,'\\n')\n",
    "print('Singular values (for last iteration)')\n",
    "print(L.diagonal(),'\\n')\n",
    "print('Model eigenvectors (matrix V, for last iteration):')\n",
    "print('     v1          v2          v3          v4')\n",
    "print(V)\n",
    "print()\n",
    "print()\n",
    "\n",
    "####MODEL COVARIANCE Matrix###\n",
    "mx1 = -1 * CVM.min()\n",
    "mx2 =  CVM.max()\n",
    "cmx = max(mx1,mx2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "\n",
    "ax.matshow(CVM, vmin=-cmx, vmax=cmx)\n",
    "CT = ax.matshow(CVM, vmin=-cmx, vmax=cmx)\n",
    "\n",
    "ax.text(-0.3, 4.1, 'For last iteration: '+ r' $\\frac{cov(m)}{\\sigma_{d}^{2}} = (G^{T} G)^{-1}$',fontsize=16)\n",
    "ax.set_xticklabels( ['nan','x','y','z','t'])\n",
    "ax.set_yticklabels( ['nan','x','y','z','t'])\n",
    "ax.set_title('Model Covariance Matrix', fontsize=16)\n",
    "\n",
    "fig.colorbar(CT,ticks=[-100, 0, 100])\n",
    "plt.show()\n",
    "\n",
    "##Singular Value Spectrum##\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "\n",
    "xlist = list(range(1,4 + 1))\n",
    "axes[0].scatter(xlist, L.diagonal(), color='r')\n",
    "axes[0].plot(xlist, L.diagonal(), color='r')\n",
    "axes[0].set_xlim((1,4))\n",
    "axes[0].set_ylim(0)\n",
    "\n",
    "axes[0].set_ylabel('singular value', fontsize = 13)\n",
    "axes[0].set_xlabel('eigenvector index k', fontsize = 13)\n",
    "axes[0].set_title('Singular Value Spectrum', fontsize=16)\n",
    "\n",
    "axes[0].grid(True)\n",
    "\n",
    "##MATRIX V##\n",
    "CV = ax.matshow(V)\n",
    "axes[1].matshow(V)\n",
    "\n",
    "axes[1].text(1.5, 3.8, 'k', fontsize=14)\n",
    "axes[1].set_xticklabels( ['nan','1','2','3','4'], fontsize=13)\n",
    "axes[1].set_yticklabels( ['nan','x','y','z','t'], fontsize=13)\n",
    "axes[1].set_title('Matrix V*', fontsize=16)\n",
    "\n",
    "fig.colorbar(CV)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b>  \n",
    "Matrix V: column k is the k-th eigenvector of the model parameter space (for last iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comprehension Questions:</h3>\n",
    "\n",
    "\n",
    "1. Repeat steps 1. to 3. for <span style=\"font-family: Courier;\">event2</span>, which is located outside the station network. How does this change the quality of your results and the covariance matrix?\n",
    "2. The German Science Foundation grants you money for one additional seismic station. Where would you put it and why? There is no single or exact solution, but some ideas make more sense than others. Show evidence that this new station improves the performance of the network.\n",
    "  \n",
    "3. Singular Value Decomposition (SVD). This is a powerful method for understanding the projection behavior of the matrix, and thus the performance and quality of the inversion experiment. For an experiment with $K$ parameters to estimate, it computes $K$ singular values $s_{k}$ (scalar). Each $s_{k}$ is associated with a $K$-vector $v_{k}$, which represents a linear combination of the unknowns. In our case, we get $K$ = 4 singular values and four eigenvectors $v_{k}$. Each eigenvector has four elements that represent weighted combinations of the parameters ($x_{s}$, $y_{s}$, $z_{s}$, $t_{s}$). SVD predicts which model parameters can be recovered robustly in the presence of noise. If an eigenvector $v_{k}$ is associated with a large singular value $s_{k}$, then the estimate for this weighted combination of model parameters will not be strongly contaminated by propagating errors. The smaller the singular value, the less accurate we expect the estimate for the parameter combination $v_{k}$ to be. (In order to improve the robustness of an inverse problem, it is a common strategy to manipulate the matrix such that $v_{k}$ associated with small sk are not even allowed to contribute to the solution.)\n",
    "\n",
    "   * Inspect the four singular values and the corresponding (4x4) matrix [$v_{k}$] (plot and screen output). For each of the four vectors, describe in words the relative weighting of parameters $x_{s}$, $y_{s}$, $z_{s}$, $t_{s}$ that they represent. According to SVD, which (combinations of) parameters should our seismic experiment be able to recover robustly? Which aspects of the earthquake source are most difficult to determine?\n",
    "   * Are these predictions consistent with what you observed in part 1?\n",
    "   * Do these findings make sense, considering the geometry of the experiment?\n",
    "   * How is matrix [$v_{k}$] affected by whether the earthquake is located inside or outside the area covered by sensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Further Reading/Materials:</h2>\n",
    "+ More on covariance matrices and error ellipse can be found on <a href='http://www.visiondummy.com/2014/04/draw-error-ellipse-representing-covariance-matrix/'>Vincent Spruyt's blog</a>.  \n",
    "+ Full <a href='https://github.com/joferkington/oost_paper_code/blob/master/error_ellipse.py'>source code</a> on how to find error ellipse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
